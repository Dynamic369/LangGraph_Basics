{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf5a589",
   "metadata": {},
   "source": [
    "### Building Chatbot with multiple tool using langraph\n",
    "\n",
    "### Aim\n",
    "Create a chatbot with tool capabilities from arxiv, wikipedia search and some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun,ArxivQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d73086",
   "metadata": {},
   "source": [
    "### Arxiv Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289cded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7305d86f",
   "metadata": {},
   "source": [
    "### Wekipedia Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0977e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper_wikipedia = WikipediaAPIWrapper(top_k_results=3,doc_content_chars_max=1000)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.invoke(\"What is Generative AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4382cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf3772",
   "metadata": {},
   "source": [
    "### Tavily Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "tavily_tool = TavilySearch(max_result=5,topic=\"general\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool.invoke(\"Provide me the latest news about Indian Politics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164eb2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine all the tools in the list\n",
    "tools = [arxiv,wiki,tavily_tool]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31737cd3",
   "metadata": {},
   "source": [
    "### Initialize my LLm model and binding it with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c98548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7af0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "\n",
    "llm_with_tools.invoke([HumanMessage(content=\"What is the recent AI news\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111851f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke([HumanMessage(content=\"What is the recent AI news\")]).tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede538a4",
   "metadata": {},
   "source": [
    "### Entire CHatbot with langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Schema\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image,display\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "## Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "# Build graph \n",
    "builder = StateGraph(State)\n",
    "\n",
    "# add node\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node('tools',ToolNode(tools))\n",
    "\n",
    "#add edges\n",
    "builder.add_edge(START,'tool_calling_llm')\n",
    "builder.add_conditional_edges(\"tool_calling_llm\",tools_condition)\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "#compile \n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af3b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "messages = graph.invoke({\"messages\":HumanMessage(content=\"What is the attention is all you need\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "messages = graph.invoke({\"messages\":HumanMessage(content=\"what is the current condition of Nepal\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075715c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "messages = graph.invoke({\"messages\":HumanMessage(content=\"What is Machine Learning\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "messages = graph.invoke({\"messages\":HumanMessage(content=\"What is MAchine Learning.Give answer from wikipedia\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e877e",
   "metadata": {},
   "source": [
    "- First we make the tools for wikipedia and arxiv using wikipedia/arxiv wrapper and query_run\n",
    "- Then for internet search we use tavily_tool from langchain_tavily\n",
    "- Combine all the tools in list form\n",
    "- Initialize the Groq model and bind it with tool\n",
    "- Creating the State schema and node definition\n",
    "- create the node (calling_with_llm, tool with the help to ToolNode)\n",
    "- add the edge (for adding tools we use tools_condition)\n",
    "- display the graph\n",
    "- query with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d9ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
