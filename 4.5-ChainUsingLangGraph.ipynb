{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b1531c",
   "metadata": {},
   "source": [
    "In this section we are going to understand how we can built a simple chain using LangGraph that uses 4 importtant concept\n",
    "- How to use chat message as graph state\n",
    "- How to use chat model in graph node.\n",
    "- How to bind tools to our LLM in chat model.\n",
    "- How to execute the tool call in our graph node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b91254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pprint import pprint # used for good representation of message\n",
    "\n",
    "messages = [AIMessage(content=f\"Hello, How can I help you\",name='LLMModel')]\n",
    "messages.append(HumanMessage(content=f\"I want to learn coding\",name='Pradum'))\n",
    "messages.append(AIMessage(content=f\"Which programming language you want to learn\",name=\"LLMModel\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn python programming language\",name='Pradum'))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30df50e",
   "metadata": {},
   "source": [
    "### Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the metadata\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf1bc7",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int,b:int) -> int:\n",
    "    \"\"\" Add a and b\n",
    "    Args:\n",
    "        a (int) :first int\n",
    "        b (int): second int\n",
    "\n",
    "    Returns:\n",
    "        int\n",
    "    \n",
    "    \"\"\"\n",
    "    return a+b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25796341",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binding tool with llm\n",
    "llm_with_tools = llm.bind_tools([add])\n",
    "\n",
    "tool_call=llm_with_tools.invoke([HumanMessage(content=f\"What is 2 plus 2\",name=\"Pradum\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using message as State\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    message:list[AnyMessage] # AnyMessage contains all type of messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a885c3",
   "metadata": {},
   "source": [
    "### Reducers\n",
    "- generally new message overwrite the previous one that why to overcome that particular issue we use Reducers with the help of this you can control the updation of messages\n",
    "- add_message is also a type of reducers that help to add the new message with old one without override it.\n",
    "- Annotated allows us to add extra metadata with type hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf35716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac147cc",
   "metadata": {},
   "source": [
    "Reducer with add_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11584746",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_messages = [AIMessage(content=f\"Hello, How can I help you\",name='LLMModel')]\n",
    "initial_messages.append(HumanMessage(content=f\"I want to learn coding\",name='Pradum'))\n",
    "initial_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c05c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message=AIMessage(content=f\"Which programming language you want to learn\",name=\"LLMModel\")\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reducer add_message is to append instead of override\n",
    "add_messages(initial_messages,ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot node funtionality\n",
    "def llm_tool(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c290f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"llm_tool\",llm_tool)\n",
    "\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "builder.add_edge(\"llm_tool\",END)\n",
    "\n",
    "graph=builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11424a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=graph.invoke({\"messages\":\"What is 2 plus 2\"})\n",
    "\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools= [add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State) \n",
    "\n",
    "builder.add_node(\"llm_tool\",llm_tool)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "# Add Edges\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "builder.add_conditional_edges(\n",
    "    \"llm_tool\",\n",
    "    # If the latest message(result) from assistamt is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message(result) from assistamt is not tool call -> tools_condition routes t o END\n",
    "    tools_condition\n",
    "\n",
    "    )\n",
    "builder.add_edge(\"tools\",END)\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b07f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f808af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=graph.invoke({\"messages\":\"What is 2 plus 2\"})\n",
    "\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0071547",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=graph.invoke({\"messages\":\"What is Generative AI\"})\n",
    "\n",
    "for message in messages['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b0351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
